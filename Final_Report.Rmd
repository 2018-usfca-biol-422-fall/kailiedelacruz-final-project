---
title: "Final Report: Your Title Here"
author: "Don Francisco"
date: "December 5, 2018"
output:
    github_document: default
bibliography: references.bib
csl: bioinformatics.csl
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

Add about 2-3 pages here. Across the whole manuscript, you should cite at least 20 peer reviewed articles.

# Methods

## Study design

sample origin: what kind of samples
how many in each group (specifics of the samples) Study design

## Sample origin and sequencing

### Study Subjects 

Working at Eastman Institute of Oral Health, University of Rochester, Yu et al. recruited 23 current smokers with the following specifics: median duration, 15 years; median intensity, 15 cigarettes per day) and 20 nonsmokers who have smoked less than 100 cigarettes in their lifetime. Yu et al. excluded subjects who were using antibiotics at the time, had a professional dental cleaning within the last three months, or diagnosed with periodontal disease, which is a serious gum infection, or cancer. To determine if each participant needed to be excluded, the participants were screened by periodontal screening and recording (PSR) index at the time of recruitment. After all subjects were recruited, they signed a consent form and filled out questionnaires in relation to the study [@yu2017effect]. 

### Biospecimen Collection 

Yu et al. obtained nine samples, including supra and subgingiva plaque, saliva, swabs from five soft tissue areas, and one nasal swab from both nostrils, from each participant. They used the procedure of the Human Micriobiome Project to collect the samples. 

### 16S rRNA Gene Sequence Analysis 

After Yu et al. extracted the DNA from each sample, they amplified the V3-V4 regions of the 16S rRNA gene and sequenced it on an Illumina MiSeq instrument using the 300 paired-end protocol. They obtained this instrument from the Institute of Genome Sciences, Genomic Resource Center, University of Maryland School of Medicine and submitted the sequence data to NCBI BioProject.

Yu et al. processed the sequence reads in order to remove low quality and short reads. The remaining reads were bunched into Operational Taxonomy Units (OTUs) at 97% identity, and OTUs with only one read were excluded. They then estimated alpha diversity as the number of OTUs, Shannon's Index, and phylogenetic diversity through averaging >20 tables (1000 reads/sample). After this, they measured taxonomic beta diversity as unweighted and weighted UniFrac distance based on the OTU table. In order to rule out batch effects, or technical sources of differences that have been added to samples during handling, they selected 19 random samples in order to example the difference within and between each batch. 

### Statistical Analysis

Yu et al. used the Wilcoxon rank-sum test to examine gastric microbiota alpha diversity and taxa-relative abundance differences between each group. They then used the Spearman correlation to examine the relationship between continuous variables. Yu et al. used Bonferroni correction to adjust for tests of multiple taxa. They also used Permutational multivariate analysis of variance in order to look at the assocation between unweighted and weighted UniFrac distance and smoking status and other demographic variables. They considered P values of less than 0.05 to be significant after the adjustment for multiple tests. 

## Computational

### FastQ Dump

Using the Yu et al. study, I downloaded the raw fastq files from NCBI with the accession number PRJNA316469 using fastq dump in a bash script. The fastq-dump function is a part of the sratoolkit that was initally downloaded. This SRA Toolkit is used to convert .sra files into other formats [@metzker2010sequencing]. For our purposes, this was the fastq format. 

### DADA2

Given the data set from the Yu et al. study, I extracted the sample and file names following the DADA2 tutorial [@callahan2016] in a separate R script. The first step in doing this was to set the base path for our input data files. This means that we provide a path variable so that it points to the input data files on my machine. After defining a path variable, I sorted the samples to ensure that they were in order. With a sorted sample set, I then extracted the sample names, making the assumption that the files have the format of “SAMPLENAME.fastq.” Following this, I specified the full path needed to take to reach each of the filenames_forward_reads. After extracting the samples, sorting them, ensuring the format of the files and defining a path for them, I inspected the read quality profiles by plotting the quality profiles of all twenty samples. I then trimmed the data from the filtered files discarding any sequences with Ns, allowing up to 3 expected errors, and cutting off the reads if quality gets as low as 2. I also used the truncLen function in trimming my data to cut off all reads at exactly 200 basepairs. This was done because our data looks at paired end reads, which refers to the two ends of the same DNA molecule. Using the truncLen function at 200 base pairs cut the reads so that only one end would be looked at, where the quality of the reads were still acceptable. To compare the read counts before and after trimming, I created a markdown table. The table showed that the number of read ins were very similar to the number of read outs in the fastq files. Next, continuing with the DADA2 pipeline, I learned the error rates of the data. Every set of data that deals with amplicons has a different set of error rates. This algorithm learns the error model of the dataset by interchanging the estimation of the error rates with the sample structure until they come together as one result. To visualize the errors, I generated plots. This provided the opportunity to check to see if error models match the data.  After visualizing the learned error rates, I dereplicated the sequences or got rid of any duplicated sequences. In further detail, dereplication combines the duplicate sequences into one individual and unique sequence with the relevant abundance that is equal to the number of reads with that sequence. This DADA2 algorithm provides a summary of the quality information that is corresponding to each unique sequence. The overall quality profile of the unique sequences is based on the average of the positional qualities from the dereplicated reads. For this study, I named the dereplicated sequences by the appropriate sample names. At this point, I ran dada to obtain multiple diagnostics about the quality of each denoised sequence variant, the number of reads in the number of unique sequences in each of the samples, etc. To visualize the information obtained from running dada, I generated a sequence table and histogram. The tables rows read “samples” and its columns read “sequence variants.” The histogram which displayed the distribution of trimmed and denoised sequences, studied the sequence length in bp in relation to the frequency.  Next, I checked for and removed any chimeras found in the data. Chimeras can be checked for by identifying them through the possibility of left and right segments to be constructed exactly from two more abundant “parent” sequences.  Using the information gathered so far, I built a table showing how many sequences remain at each step of the pipeline. The columns of the table read “Input,” “Filtered,” “Denoised,” “Sequence Table,” and “Non-chimeric.” Following this, I assigned taxonomy to each sequence variant based on a supplied training set made up of unknown sequences. I exported the cleaned, trimmed, filtered, and denoised sequence variants in order to build a phylogeny to allow for the visualization of the taxonomy. I extracted the sequences to fasta because this is the format that is needed to build a phylogeny.

### Phyloseq 

To begin building a phylogeny, I read in the metadata and the phylogeny. I then constructed a phyloseq object with all of the appropriate data, such as phylogeny from sequence variants, taxonomy for each sequence variant and metadata for each sample. In general, a phyloseq tool can be used to import, analyze, and graphically display phylogenetic sequencing data. It is helpful in reproducible interactive analysis and graphics of microbiome census data [@mcmurdie2013]. However, for this study, I continued by melting the phyloseq object, which puts all of the data for every sample in one file. I then saved both the phyloseq_obj and melted_obj with the .Rdata format. In doing this, 

Using this data, I analyzed the difference in bacterial communities in terms of their taxonomy between the Fkey sample set and the Jkey sample set. I also analyzed the variation in abundances of the focal genera between each individual that was sampled. In doing so, these files were made compressed and able to be quickly loaded. These saved .Rdata files were loaded on the .Rmd file and used for analysis. Using the data from these files, I looked at the difference in bacterial communities, specifically the difference in phyla between participants with different smoking statuses. I also analyzed the variation of abundances of the focal family between the smoking individuals, in terms of env_material. In doing so, I needed the data that related to the taxonomy of all of the env_material samples as well as the abundances of sequences of the important taxonomy that relate to the samples.

# Results

## Subsections are ok in the results section too

```{r bar-graph-1, echo = FALSE}
melted_obj %>%
  group_by(Phylum, smoker) %>%
  summarize(sum_count = sum(Abundance)) %>%
  ggplot(aes(x = Phylum,
             y = sum_count,
             fill = smoker)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Count of the Different Phyla in Terms of Smoking Status") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r bar-graph-2, echo = FALSE}
melted_obj %>%
  group_by(env_material, Phylum, smoker) %>%
  summarize(sum_count = sum(Abundance)) %>%
  filter(smoker == "smoker") %>%
  ggplot(aes(x = Phylum,
             y = sum_count,
             fill = env_material)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Count of the Different Phyla in terms of env_material") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r bar-graph-3, echo = FALSE}
melted_obj %>%
  group_by(env_material, Phylum, smoker) %>%
  summarize(sum_count = sum(Abundance)) %>%
  filter(smoker == "smoker") %>%
  filter(Phylum == "Firmicutes") %>%
  ggplot(aes(x = Phylum,
             y = sum_count,
             fill = env_material)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Counts of Firmicutes in Terms of env_material") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r bar-graph-4, echo = FALSE}
melted_obj %>%
  group_by(env_material, Phylum, smoker, Family) %>%
  summarize(sum_count = sum(Abundance)) %>%
  filter(smoker == "smoker") %>%
  filter(Phylum == "Firmicutes") %>%
  ggplot(aes(x = Family,
             y = sum_count,
             fill = env_material)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Counts of the Different Families in Terms of env_material") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r bar-graph-5, echo = FALSE}
melted_obj %>%
  group_by(env_material, Phylum, smoker, Family) %>%
  summarize(sum_count = sum(Abundance)) %>%
  filter(smoker == "smoker") %>%
  filter(Family == "Streptococcaceae") %>%
  ggplot(aes(x = Family,
             y = sum_count,
             fill = env_material)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Counts of Streptococcaceae in Terms of env_material") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

```{r bar-graph-6, echo = FALSE}
melted_obj %>%
  group_by(env_material, Phylum, smoker, Family, host_subject_id) %>%
  summarize(sum_count = sum(Abundance)) %>%
  filter(smoker == "smoker") %>%
  filter(Family == "Streptococcaceae") %>%
  ggplot(aes(x = host_subject_id,
             y = sum_count,
             fill = env_material)) +
  geom_col(position = "dodge") +
  ggtitle("Abundance Counts of host_subject_id in Terms of Streptococcaceae and env_material") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


```{r load-packages-and-data, echo = FALSE}
# load packages as needed
library("dplyr")
library("tidyr")
library("ggplot2")
library("knitr")
library("citr")

# load data produced from analysis scripts using
# something like load("output/processed_data.Rdata")
load("output/phyloseq_obj.Rdata")
load("output/melted_obj.Rdata")
```

In addition to a minimum of 5-8 figures/tables (and associated captions), you should include sufficient text in this section to describe what your findings were. Remember that in the results section you just describe what you found, but you don't interpret it - that happens in the discussion. 2-3 pages.

# Discussion

Add around 3-4 pages interpreting your results and considering future directions one might take in analyzing these data.

# Sources Cited
